{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a deep learning model the clones the driving behavior "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this project I have worked on a deep learning model based on LeNet architecture by Yan LeCun to clone the driving behavior of a car.**\n",
    "\n",
    "\n",
    "I have tested this model on Udacity simulator for a complete lap\n",
    "\n",
    "\n",
    "In the following I will be explaining each part of the project ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Project Pipeline Stepts:\n",
    "\n",
    "**Step 1:** Load The data\n",
    "\n",
    "**Step 2:** Split data into trainig and validation sets\n",
    "    \n",
    "**Step 3:** Define a generator function to be used through training\n",
    "\n",
    "**Step 4:** Use the defined generator in step 3 for training set and validation set\n",
    "    \n",
    "**Step 5:** Using keras, build a regression model based on LeNet architecture to predict the steering angle\n",
    "    \n",
    "In the next, I will be giving some details related to each steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Environment:\n",
    "* AWS carnd Instance\n",
    "* Python 3.6.4\n",
    "* Anaconda 4.4.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Load The data\n",
    "\n",
    "Here I am using the python csv library to read the csv file generated from the simulator.\n",
    "This file contains paths to three camera images captured through the training, steering angle, throttle, break, and vehicle speed.\n",
    "\n",
    "We will ignore the throttle, break, and speed measurements.\n",
    "\n",
    "We will use the images as the feature set and the steering angle as the label set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "        \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Split data into trainig and validation sets\n",
    "\n",
    "Here I am splitting the data into two set, training set which is 80% of the data, and validation set which is 20% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8447\n",
      "2112\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "print(len(train_samples))\n",
    "print(len(validation_samples))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            steering_angles = []\n",
    "            correction = 0.1889\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                # Reading center image and steering angle\n",
    "                name = \"data/IMG/\"+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                if center_image is not None:\n",
    "                    center_image = cv2.cvtColor(center_image, cv2.COLOR_BGR2RGB)\n",
    "                    images.append(center_image)\n",
    "                    \n",
    "                    center_angle = float(batch_sample[3])\n",
    "                    steering_angles.append(center_angle)\n",
    "                    \n",
    "                    \n",
    "                    # Making data augmentation - Flippiong readings\n",
    "                    center_image = np.fliplr(center_image)\n",
    "                    images.append(center_image)\n",
    "                    \n",
    "                    center_angle = - center_angle\n",
    "                    steering_angles.append(center_angle)\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                else :\n",
    "                    print(\"Center Image \" +  name + \" is NONE\")\n",
    "                    \n",
    "\n",
    "                    \n",
    "                # Reading left image and steering angle\n",
    "                name = \"data/IMG/\"+batch_sample[1].split('/')[-1]\n",
    "                left_image = cv2.imread(name)\n",
    "                if left_image is not None:\n",
    "                    left_image = cv2.cvtColor(left_image, cv2.COLOR_BGR2RGB)\n",
    "                    images.append(left_image)\n",
    "                    \n",
    "                    center_angle = float(batch_sample[3])\n",
    "                    left_angle = center_angle + correction\n",
    "                    steering_angles.append(left_angle)\n",
    "                    \n",
    "                    \n",
    "                    # Making data augmentation - Flippiong readings\n",
    "                    left_image = np.fliplr(left_image)\n",
    "                    images.append(left_image)\n",
    "                    \n",
    "                    left_angle = - left_angle\n",
    "                    steering_angles.append(left_angle)\n",
    "                \n",
    "                else :\n",
    "                    print(\"Left Image \" +  name + \" is NONE\")                 \n",
    "                \n",
    "                \n",
    "                # Reading right image and steering angle\n",
    "                name = \"data/IMG/\"+batch_sample[2].split('/')[-1]\n",
    "                right_image = cv2.imread(name)\n",
    "                if right_image is not None:\n",
    "                    right_image = cv2.cvtColor(right_image, cv2.COLOR_BGR2RGB)\n",
    "                    images.append(right_image)\n",
    "                    \n",
    "                    center_angle = float(batch_sample[3])\n",
    "                    right_angle = center_angle - correction\n",
    "                    steering_angles.append(right_angle)\n",
    "                    \n",
    "                    \n",
    "                    # Making data augmentation - Flippiong readings\n",
    "                    right_image = np.fliplr(right_image)\n",
    "                    images.append(right_image)\n",
    "                    \n",
    "                    right_angle = - right_angle\n",
    "                    steering_angles.append(right_angle)\n",
    "                \n",
    "                else :\n",
    "                    print(\"Right Image \" +  name + \" is NONE\")  \n",
    "                    \n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(steering_angles)\n",
    "            \n",
    "            yield shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augmentation(image):\n",
    "    flipped_image = np.fliplr(image)\n",
    "    hsv_image = cv2.cvtColor(flipped_image, cv2.COLOR_RGB2HSV) #convert it to hsv\n",
    "\n",
    "    h, s, v = cv2.split(hsv_image)\n",
    "    v += 100\n",
    "    final_hsv_image = cv2.merge((h, s, v))\n",
    "\n",
    "    aug_image = cv2.cvtColor(final_hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return aug_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "8256/8447 [============================>.] - ETA: 0s - loss: 0.4918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8448/8447 [==============================] - 22s - loss: 0.4844 - val_loss: 0.0698\n",
      "Epoch 2/7\n",
      "8448/8447 [==============================] - 20s - loss: 0.0993 - val_loss: 0.0840\n",
      "Epoch 3/7\n",
      "8448/8447 [==============================] - 20s - loss: 0.0805 - val_loss: 0.0683\n",
      "Epoch 4/7\n",
      "8448/8447 [==============================] - 20s - loss: 0.0786 - val_loss: 0.0766\n",
      "Epoch 5/7\n",
      "8448/8447 [==============================] - 20s - loss: 0.0811 - val_loss: 0.0646\n",
      "Epoch 6/7\n",
      "8634/8447 [==============================] - 21s - loss: 0.0748 - val_loss: 0.0578\n",
      "Epoch 7/7\n",
      "8448/8447 [==============================] - 20s - loss: 0.0681 - val_loss: 0.0697\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, Activation, Cropping2D, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(3,160,320)))\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,20), (0,0))))\n",
    "\n",
    "model.add(Convolution2D(6, 5, 5, border_mode='valid'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='valid'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "# model.add(Convolution2D(32, 3, 3, border_mode='valid'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# # model.add(Dropout(0.5))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Convolution2D(16, 2, 2, border_mode='valid'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# # model.add(Dropout(0.5))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(120))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(84))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(32))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(16))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# model.fit(X_train, y_train, nb_epoch = 3, validation_split = 0.2, shuffle=True, verbose=1)\n",
    "model.fit_generator(train_generator,\n",
    "                    samples_per_epoch=len(train_samples),\n",
    "                    validation_data=validation_generator,\n",
    "                    nb_val_samples=len(validation_samples),\n",
    "                    nb_epoch=7,\n",
    "                    verbose=1)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
